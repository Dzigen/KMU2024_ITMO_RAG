{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/dzigen/Desktop/ITMO/ВКР/КМУ2024/\")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.retrievers.e5 import E5Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E5-model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading query E5-model...\n",
      "Loading document E5-model...\n"
     ]
    }
   ],
   "source": [
    "retriever = E5Retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = retriever.model.embed_documents([\"Hello world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7857142857142857"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1/2)*np.log2(1/2)) + ((1/2)*np.log2(1/2))* (4/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FiD-model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fid_model import FiDT5\n",
    "import transformers\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'google-t5/t5-base'\n",
    "t5 = transformers.T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = transformers.T5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FiDT5(t5.config)\n",
    "model.encoder.n_passages = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.randint(0, 255, size=(2,2,512))\n",
    "attention_mask = torch.randint(0, 255, size=(2,2,512))\n",
    "labels = torch.randint(0, 255, size=(2,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_out = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_out = model(input_ids=input_ids,\n",
    "          attention_mask=attention_mask,\n",
    "          labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColBERT test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "N = 3\n",
    "Q_L = 2\n",
    "D_L = 4\n",
    "K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) torch.Size([3, 4, 3])\n",
      "torch.Size([2, 2]) torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "q_batch = F.normalize(torch.randn(B,Q_L,K), dim=-1)\n",
    "q_batch.requires_grad=True\n",
    "q_mask = torch.randint(0,2,size=(B,Q_L)).bool()\n",
    "d_batch = F.normalize(torch.randn(N,D_L,K), dim=-1)\n",
    "d_batch.requires_grad=True\n",
    "d_mask = torch.randint(0,2,size=(N,D_L)).bool()\n",
    "\n",
    "print(q_batch.shape, d_batch.shape)\n",
    "print(q_mask.shape, d_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 4])\n",
      "torch.Size([3, 2, 4])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([3])\n",
      "torch.Size([3, 2, 4])\n",
      "torch.Size([3, 2, 4])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "batch_scores = torch.tensor([], requires_grad=True)\n",
    "for i in range(q_batch.shape[0]):\n",
    "    C = F.cosine_similarity(q_batch[i].unsqueeze(1).unsqueeze(1), d_batch, dim=-1)\n",
    "    C = C.permute((1,0,2))\n",
    "    print(C.shape)\n",
    "\n",
    "    d_masked_C = C.masked_fill(d_mask.unsqueeze(1), -100)\n",
    "    print(d_masked_C.shape)\n",
    "\n",
    "    max_C = d_masked_C.max(dim=-1).values\n",
    "    print(max_C.shape)\n",
    "\n",
    "    q_masked_C = max_C.masked_fill(q_mask[i].unsqueeze(0), 0)\n",
    "    print(q_masked_C.shape)\n",
    "\n",
    "    scores = q_masked_C.sum(dim=-1)\n",
    "    print(scores.shape)\n",
    "\n",
    "    batch_scores = torch.cat((batch_scores, scores.unsqueeze(0)), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3669, -0.5969, -0.8911],\n",
       "        [-0.1125,  0.3626, -0.2524]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = batch_scores.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_batch.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b_i in range(q.shape[0]):\n",
    "    batch_scores = []\n",
    "    for doc_i in range(d.shape[1]):\n",
    "        doc_scores = torch.tensor([\n",
    "            (d[b_i][doc_i] - q[b_i][q_token_i]).pow(2).sum().sqrt() \n",
    "            for q_token_i in range(q.shape[1])], requires_grad=True)\n",
    "        \n",
    "        print(doc_scores.shape)\n",
    "        print(d_mask[b_i][doc_i].shape)\n",
    "\n",
    "        max_score = torch.masked_select(\n",
    "            doc_scores, d_mask[b_i][doc_i]).max(0).values\n",
    "\n",
    "        print(doc_scores)\n",
    "        print(max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4106,  0.1958, -0.5337,  0.3719, -0.4051, -0.6870, -0.8315,  0.4174,\n",
       "        -1.0673,  0.5532,  0.8065,  0.3561,  0.0629, -0.3530,  0.8857,  0.9097,\n",
       "        -0.5392, -1.3984,  1.7648,  1.2462, -0.5269, -0.4240,  1.6104,  0.3616,\n",
       "         0.6950,  1.5886, -0.4794,  0.2703, -0.8660, -0.8782,  0.5527,  1.4357])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3448, -2.2135,  0.2222, -1.6303,  0.2953,  1.2714,  0.4842, -0.9713,\n",
       "         1.7690, -2.6323, -1.2720, -1.0291, -1.0879,  0.2451,  1.1824, -0.3049,\n",
       "         0.4246,  1.2510, -1.0612, -2.6815, -0.0453,  1.1504, -2.3646,  1.5032,\n",
       "        -2.3634, -2.1664,  0.5274,  1.0541,  1.1237,  1.6425, -0.1971, -2.2892])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][0] - q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7554, -2.0177, -0.3115, -1.2583, -0.1098,  0.5844, -0.3473, -0.5539,\n",
       "         0.7017, -2.0791, -0.4655, -0.6730, -1.0251, -0.1079,  2.0681,  0.6048,\n",
       "        -0.1146, -0.1474,  0.7036, -1.4353, -0.5723,  0.7263, -0.7542,  1.8648,\n",
       "        -1.6684, -0.5778,  0.0480,  1.3244,  0.2577,  0.7643,  0.3556, -0.8535])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 1]) torch.Size([4, 1, 10, 32])\n"
     ]
    }
   ],
   "source": [
    "q_un = q.unsqueeze(2)\n",
    "d_un = d.unsqueeze(1)\n",
    "\n",
    "print(q_un.shape, d_un.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (10) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mq_un\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md_un\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (10) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "q_un - d_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
