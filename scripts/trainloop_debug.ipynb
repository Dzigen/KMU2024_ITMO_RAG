{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import gc\n",
    "import json\n",
    "from time import time\n",
    "import os\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from dataclasses import dataclass\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/dzigen/Desktop/ITMO/ВКР/КМУ2024/\")\n",
    "\n",
    "from src.readers.fid import FiDReader\n",
    "from src.readers.archs.fid_model import FiDT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = transformers.T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "model = FiDT5(t5.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = FiDReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = torch.randint(0, 255, size=(4,1,512))\n",
    "mask = torch.randint(0, 255, size=(4,1,512))\n",
    "labels = torch.randint(0, 255, size=(4,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward 2\n",
      "init dimension:  torch.Size([4, 1, 512])\n",
      "2d resize:  torch.Size([4, 512])\n",
      "forward 3\n",
      "2d resize:  torch.Size([4, 512])\n",
      "---\n",
      "candidates flat:  torch.Size([4, 512])\n",
      "encoder output  torch.Size([4, 512, 768])\n",
      "candidates concatenation:\n",
      "last_hidden_state torch.Size([4, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "model(input_ids=ids, attention_mask=mask, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.randint(0, 255, size=(2,2,512))\n",
    "attention_mask = torch.randint(0, 255, size=(2,2,512))\n",
    "labels = torch.randint(0, 255, size=(2,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = reader.model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.tokenizer.batch_decode(out, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward 2\n",
      "init dimension:  torch.Size([2, 2, 512])\n",
      "2d resize:  torch.Size([2, 1024])\n",
      "forward 3\n",
      "2d resize:  torch.Size([2, 1024])\n",
      "---\n",
      "candidates flat:  torch.Size([4, 512])\n",
      "encoder output  torch.Size([4, 512, 768])\n",
      "candidates concatenation:\n",
      "last_hidden_state torch.Size([2, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "out = reader.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Reader Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Retriever Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0436)\n",
      "tensor(1.0436)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "output_score = torch.eye(6) #torch.randn(6,6)\n",
    "targets = torch.arange(0,6)\n",
    "\n",
    "auto_loss = criterion(output_score, targets)\n",
    "print(auto_loss)\n",
    "\n",
    "manual_loss = torch.mean(-torch.log(F.softmax(output_score, dim=1).gather(1, targets.view(-1,1)) ))\n",
    "print(manual_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0261)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_topk_loss = 0.2\n",
    "reader_k_loss = torch.tensor([[0.9,0.1,0.5]])\n",
    "retriever_k_scores = torch.tensor([[5,1,3]])\n",
    "criterion(reader_topk_loss, reader_k_loss, retriever_k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6946)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_topk_loss = 0.8\n",
    "reader_k_loss = torch.tensor([[0.9,0.8,1]])\n",
    "retriever_k_scores = torch.tensor([[5,3,3]])\n",
    "criterion(reader_topk_loss, reader_k_loss, retriever_k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2,3],[4,5,6]]).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reader + Frozen Retriever Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.randint(0,255, size=(1,2,512))\n",
    "attention_mask = torch.randint(0,2, size=(1,2,512))\n",
    "\n",
    "labels = torch.randint(0,255, size=(1,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [204, 21820, 296, 1], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.tokenizer(\" 2 hello world\", add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward 2\n",
      "init dimension:  torch.Size([1, 2, 512])\n",
      "2d resize:  torch.Size([1, 1024])\n",
      "forward 3\n",
      "2d resize:  torch.Size([1, 1024])\n",
      "---\n",
      "candidates flat:  torch.Size([2, 512])\n",
      "encoder output  torch.Size([2, 512, 768])\n",
      "candidates concatenation:\n",
      "last_hidden_state torch.Size([1, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "output = reader.model(input_ids=input_ids,attention_mask=attention_mask, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 32128])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2608e-06, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(output.logits, dim=-1)[0][0][111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2608e-06, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(output.logits.view(512, 32128), dim=-1).gather(1,labels)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.1423, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = torch.mean(-torch.log(F.softmax(output.logits, dim=-1).gather(2,labels.view(1, 512, -1))).view(1, 512), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15.1423], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2608e-06, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(output.logits, dim=-1)[0][0][111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzigen/miniconda3/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5.py:246: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "reader = FiDReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[21820,     1,     0,  ...,     0,     0,     0],\n",
       "        [  296,     1,     0,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 0,  ..., 0, 0, 0],\n",
       "        [1, 1, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.tokenizer([\"hello\", \"world\"], max_length=512, padding='max_length', \n",
    "            return_tensors='pt', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = reader.tokenizer(\"hello\", \"world\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_reshape = output[:,:-1].contiguous().view(-1, output.shape[-1])\n",
    "                trg_batch = trg_batch[:, 1:].contiguous().view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Reader + Retriever Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JoinLoss:\n",
    "    def __init__(self, r=1) -> None:\n",
    "        self.temp = r\n",
    "\n",
    "    def __call__(self, reader_topk_loss, reader_k_loss, retriever_k_scores):\n",
    "        '''\n",
    "        params:\n",
    "            reader_topk_loss: 1\n",
    "            reader_k_loss: BxN\n",
    "            retriever_k_scores: BxN\n",
    "\n",
    "        output:\n",
    "            scores: 1\n",
    "        '''\n",
    "\n",
    "        retriever_part = torch.mean(torch.log(torch.sum(\n",
    "            F.softmax(retriever_k_scores / self.temp, dim=1)*reader_k_loss, dim=1)))\n",
    "\n",
    "        return reader_topk_loss + retriever_part\n",
    "    \n",
    "    def k_loss(self, reader_logits, labels):\n",
    "        '''\n",
    "        params:\n",
    "            reader_logits: BxNxLxVOCAB_SIZE\n",
    "            labels: BxL\n",
    "\n",
    "        output:\n",
    "            scores: BxN\n",
    "        '''\n",
    "        bsz, k, seq_len = reader_logits.shape[0], reader_logits.shape[1], reader_logits.shape[2]\n",
    "\n",
    "        return torch.mean(-torch.log(F.softmax(\n",
    "            reader_logits.logits, dim=-1).gather(3,labels.view(bsz, 1, seq_len, -1))).view(bsz, k, seq_len), dim=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
